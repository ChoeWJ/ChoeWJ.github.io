---
layout: single
title: "ì›¹ í¬ë¡¤ë§ ì‹œì‘í•˜ê¸°"
categories: web_crawling
tag: [python, automation, web_crawling]
author_profile: false
# sidebar:
#   nav: "counts"
# search: false
# redirect_from:
#   - /coding/first-posting
use_math: true
---

# ğŸ† ì›¹ í¬ë¡¤ë§ ì‹œì‘í•˜ê¸°

## ğŸ‹ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

`vscode í™˜ê²½ ê¸°ì¤€`

```sh
pip install notebook ipyekrnel requests bs4 lxml selenium webdriver-manager scrapy pandas openpyxl
```

## ğŸ‹ BeautifulSoup

### ğŸŒ¼ ì‚¬ìš© ë°©ë²•

```python
soup = BeautifulSoup(markup, parser, **kwargs)
```

- `markup`: HTML/XML ë¬¸ìì—´
- `parser`: HTML/XMLì„ í•´ì„í•˜ëŠ” íŒŒì„œ
- `**kwargs`: ì¶”ê°€ ì˜µì…˜ (ex. from_encoding)

### ğŸŒ¼ ì£¼ìš” ë©”ì„œë“œ

- #### ğŸ¯ find

  - íƒœê·¸ ê²€ìƒ‰
  - `find("p")`: ì²« ë²ˆì§¸ <p> íƒœê·¸ ì°¾ê¸°
  - `find_all("p")`: ëª¨ë“  <p> íƒœê·¸ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜

- #### ğŸ¯ select

  - CSS ì„ íƒìë¡œ ê²€ìƒ‰
  - `select("p")`: ëª¨ë“  <p> íƒœê·¸ ì°¾ê¸°
  - `select(".content")`: class="content"ì¸ ìš”ì†Œ ì°¾ê¸°
  - `select("#second")`: id="second"ì¸ ìš”ì†Œ ì°¾ê¸°
  - `select("head > title")`: ê³„ì¸µ êµ¬ì¡°ë¡œ ê²€ìƒ‰

- #### ğŸ¯ text

  - í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
  - `p.text`: ì²« ë²ˆì¨° <p> íƒœê·¸ì˜ í…ìŠ¤íŠ¸ ë‚´ìš©
  - `p.get_text()`: ìœ„ì™€ ë™ì¼

- #### ğŸ¯ íƒœê·¸ ì†ì„± ê°’ ê°€ì ¸ì˜¤ê¸°
  - `p["class"]`: class ì†ì„± ê°’ ê°€ì ¸ì˜¤ê¸°
  - `find(id="second")["id"]`: id ì†ì„± ê°’ ê°€ì ¸ì˜¤ê¸°

### ğŸŒ¼ ì£¼ìš” ì˜µì…˜

- #### .text.strip()

  - HTMLíƒœê·¸ ì œê±° í›„ í…ìŠ¤íŠ¸ë§Œ ê°€ì ¸ì˜¤ê³  ì•ë’¤ ê³µë°± ì œê±°

- #### find_all(..., limit=3)

  - ì²˜ìŒ 3ê°œë§Œ ê°€ì ¸ì˜¤ê¸°

- #### find(..., recursive=False)
  - ì²« ë²ˆì§¸ ìì‹ë§Œ ê²€ìƒ‰

```python
import requests  # requests ë¼ì´ë¸ŒëŸ¬ë¦¬

from urllib.request import urlopen  # ë¹ ë¥¸ url ìš”ì²­ ë¼ì´ë¸ŒëŸ¬ë¦¬
from urllib.error import HTTPError, URLError  # error ìºì¹˜ ë¼ì´ë¸ŒëŸ¬ë¦¬
from bs4 import BeautifulSoup  # BeautifulSoup ë¼ì´ë¸ŒëŸ¬ë¦¬
```

## ğŸ‹ íŒŒì„œì˜ ì¢…ë¥˜

| ì¢…ë¥˜ | `html.parser `           | `lxml`                                            | `html5lib`               |
| ---- | ------------------------ | ------------------------------------------------- | ------------------------ |
| ì„¤ëª… | python ê¸°ë³¸ íŒŒì„œ         | ë¹ ë¥´ê³  ê°•ëµí•œ XML/HTML íŒŒì„œ                       | HTML5 í‘œì¤€ì„ ë”°ë¥´ëŠ” íŒŒì„œ |
| ì¥ì  | ë‚´ì¥ ë¼ì´ë¸ŒëŸ¬ë¦¬          | ê°€ì¥ ë¹ ë¦„, HTML/XML ëª¨ë‘ ì§€ì›, ì˜¤ë¥˜ì²˜ë¦¬ ëŠ¥ë ¥ ìš°ìˆ˜ | ê°€ì¥ ì •í™•                |
| ë‹¨ì  | ì¼ë¶€ HTML ì²˜ë¦¬ ëŠ¥ë ¥ ì•½í•¨ | ì¶”ê°€ ì„¤ì¹˜ í•„ìš”                                    | ê°€ì¥ ëŠë¦¼                |

### ğŸŒ¼ html.parser

```python
url = 'https://ko.wikipedia.org/wiki/%EC%9B%B9_%ED%81%AC%EB%A1%A4%EB%9F%AC'  # ìœ„í‚¤í”¼ë””ì•„ ì›¹ í¬ë¡¤ëŸ¬ ì •ë³´ ì‚¬ì´íŠ¸
response = requests.get(url)  # ì›¹ í˜ì´ì§€ ìš”ì²­
soup = BeautifulSoup(response.text, 'html.parser')  # í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥

print(soup.title.text)  # <title> íƒœê·¸ë¥¼ í…ìŠ¤íŠ¸ë¡œ ì¶œë ¥
print((soup.find("h1").text))  # ì²« ë²ˆì§¸ <h1> íƒœê·¸ ë‚´ìš©ì„ ì¶œë ¥
```

ì¶œë ¥ ê²°ê³¼

ì›¹ í¬ë¡¤ëŸ¬ - ìœ„í‚¤ë°±ê³¼, ìš°ë¦¬ ëª¨ë‘ì˜ ë°±ê³¼ì‚¬ì „<br>
ì›¹ í¬ë¡¤ëŸ¬

### ğŸŒ¼ lxml

```python
url = 'https://ko.wikipedia.org/wiki/%EC%9B%B9_%ED%81%AC%EB%A1%A4%EB%9F%AC'  # ìœ„í‚¤í”¼ë””ì•„ ì›¹ í¬ë¡¤ëŸ¬ ì •ë³´ ì‚¬ì´íŠ¸
response = requests.get(url)  # ì›¹ í˜ì´ì§€ ìš”ì²­
soup = BeautifulSoup(response.text, 'lxml')  # í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥

print(soup.title.text)  # <title> íƒœê·¸ë¥¼ í…ìŠ¤íŠ¸ë¡œ ì¶œë ¥
print((soup.find("h1").text))  # ì²« ë²ˆì§¸ <h1> íƒœê·¸ ë‚´ìš©ì„ ì¶œë ¥
```

ì¶œë ¥ ê²°ê³¼

ì›¹ í¬ë¡¤ëŸ¬ - ìœ„í‚¤ë°±ê³¼, ìš°ë¦¬ ëª¨ë‘ì˜ ë°±ê³¼ì‚¬ì „<br>
ì›¹ í¬ë¡¤ëŸ¬

### ğŸŒ¼ html5lib

```python
url = 'https://ko.wikipedia.org/wiki/%EC%9B%B9_%ED%81%AC%EB%A1%A4%EB%9F%AC'  # ìœ„í‚¤í”¼ë””ì•„ ì›¹ í¬ë¡¤ëŸ¬ ì •ë³´ ì‚¬ì´íŠ¸
response = requests.get(url)  # ì›¹ í˜ì´ì§€ ìš”ì²­
soup = BeautifulSoup(response.text, 'html5lib')  # í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥

print(soup.title.text)  # <title> íƒœê·¸ë¥¼ í…ìŠ¤íŠ¸ë¡œ ì¶œë ¥
print((soup.find("h1").text))  # ì²« ë²ˆì§¸ <h1> íƒœê·¸ ë‚´ìš©ì„ ì¶œë ¥
```

ì¶œë ¥ ê²°ê³¼

ì›¹ í¬ë¡¤ëŸ¬ - ìœ„í‚¤ë°±ê³¼, ìš°ë¦¬ ëª¨ë‘ì˜ ë°±ê³¼ì‚¬ì „<br>
ì›¹ í¬ë¡¤ëŸ¬

### ğŸŒ¼ ì˜ˆì™¸ ì²˜ë¦¬

- #### ğŸ¯ HTTPError
  - í˜ì´ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜, URL í•´ì„ì—ì„œ ì—ëŸ¬ê°€ ë°œìƒí•œ ê²½ìš°
  - ì„œë²„ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°

```python
try:
    html = urlopen("https://ko.wikipedia.org/wiki/%EC%9B%B9_%ED%81%AC%EB%A1%A4%EB%9F%AC123")  # ì—ëŸ¬ ë°œìƒì„ ìœ„í•´ ë§¨ ë’¤ì— 123ì„ ë¶™ì„
except HTTPError as e:
    print("The server returned an HTTP error")
```

ì¶œë ¥ ê²°ê³¼

The server returned an HTTP error

- #### ğŸ¯ URLError
  - ì„œë²„ê°€ ë‹¤ìš´ë˜ì—ˆì„ ë•Œ
  - URLì— ì˜¤íƒ€ê°€ ìˆì„ë–„

```python
try:
    html = urlopen("https:/ko.wikipedia.org/wiki/%EC%9B%B9_%ED%81%AC%EB%A1%A4%EB%9F%AC")  # ì—ëŸ¬ ë°œìƒì„ ìœ„í•´ https:// ì—ì„œ / í•˜ë‚˜ë¥¼ ëºŒ
except URLError as e:
    print("The server could not be found!")
```

ì¶œë ¥ ê²°ê³¼

The server could not be found!

- #### ğŸ¯ AttributeError
  - ì¡´ì¬í•˜ì§€ ì•ŠëŠ” íƒœê·¸ì— ì ‘ê·¼ì„ ì‹œë„í•  ë•Œ

```python
try:
    bad_content = soup.non_exist.another
except AttributeError as e:
    print("Tag was not found")
else:
    if bad_content is None:
        print("Tag was not found")
    else:
        print(bad_content)
```

ì¶œë ¥ ê²°ê³¼

Tag was not found

### ğŸŒ¼ ì˜ˆì™¸ ì²˜ë¦¬ í•¨ìˆ˜ ìƒì„±

```python
def get_error(url):
    try:
        response = requests.get(url)  # ì›¹ í˜ì´ì§€ ìš”ì²­
    except HTTPError as e:
        return None  # ì˜¤ë¥˜ ë°œìƒ ì‹œ None ë°˜í™˜
    except URLError as e:
        return None  # ì˜¤ë¥˜ ë°œìƒ ì‹œ None ë°˜í™˜
    try:
        soup = BeautifulSoup(response.text, 'html.parser')  # HTML íŒŒì‹±
        title = soup.find("h1")  # í˜ì´ì§€ ë‚´ ì²« ë²ˆì§¸ <h1> íƒœê·¸ íƒìƒ‰
    except AttributeError as e:
        return None  # ì˜¤ë¥˜ ë°œìƒ ì‹œ None ë°˜í™˜
    return title


title = get_error("https://ko.wikipedia.org/wiki/%EC%9B%B9_%ED%81%AC%EB%A1%A4%EB%9F%AC")  # get_error í•¨ìˆ˜ ì‹¤í–‰
if title is None:
    print("Title could not be found")  # ì œëª©ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° ì—ëŸ¬ ë©”ì„¸ì§€ ì¶œë ¥
else:
    print(title.get_text())  # ì œëª©ì„ ì°¾ì•„ì„œ í…ìŠ¤íŠ¸ ì¶œë ¥
```

ì¶œë ¥ ê²°ê³¼

ì›¹ í¬ë¡¤ëŸ¬
