---
layout: single
title: "[ML-DL] 위클리 페이퍼 - KFold"
categories:
  - ML-DL
  - ML
tag: [ML-DL]
author_profile: false
sidebar:
  nav: "counts"
# protect: true
contact_info: choewj117@gmail.com
# search: false
# redirect_from:
#   - /coding/first-posting
use_math: true
---

# K-폴드 교차 검증에서 K의 값을 선택할 때 고려해야 할 점은 무엇인가요?

<img src="{{ '/assets/images/kfold.png' | relative_url }}" alt="이미지 설명" width=800 height=600>

K-Fold 교차 검증은 머신러닝 모델의 성능을 안정적으로 평가하기 위해 데이터셋을 여러 조각으로 나누어 테스트하는 <font color="#1E90FF">강력한 방법</font>이다. 단일 테스트 세트를 사용할 때보다 더 신뢰할 수 있는 성능 추정치를 제공하며, 모델이 새로운 데이터에 얼마나 잘 일반화되는지를 알려준다.

## 모델 성능 평가와 평균 제곱 오차(MSE)

모델의 성능을 평가하려면 예측값이 실제 데이터와 얼마나 가까운지를 측정해야 한다. 가장 널리 사용되는 지표는 <font color="#FFD700">평균 제곱 오차(MSE)</font>로, 다음과 같이 계산된다:

$ \text{MSE} = \frac{1}{n} \sum\_{i=1}^n (y_i - f(x_i))^2 $

여기서 $\( n \)$은 관측값의 총 개수, $\( y_i \)$는 실제 반응값, $\( f(x_i) \)$는 예측값이다. MSE는 예측이 실제값에 가까울수록 작아지며, 모델의 정확도를 직관적으로 보여준다. 실무에서는 이 MSE를 계산해 모델이 보지 못한 데이터에서 얼마나 잘 작동하는지를 평가한다.

## 단일 테스트 세트의 한계

데이터셋을 훈련 세트와 테스트 세트로 나누어 모델을 학습시키고 <font color="#32CD32">테스트 MSE</font>를 계산하는 방식이 일반적이다. 테스트 MSE는 모델의 일반화 능력을 보여주지만, 단일 테스트 세트를 사용할 경우 문제가 있다. 선택된 훈련 및 테스트 세트에 따라 테스트 MSE가 크게 달라질 수 있어, 성능 추정치가 불안정해진다. 이를 해결하려면 데이터를 여러 번 나누어 모델을 학습시키고, 각기 다른 훈련-테스트 세트로 테스트 MSE를 계산한 뒤 평균을 내는 방법이 필요하다. 여기서 K-Fold 교차 검증이 빛을 발한다.

## K-Fold 교차 검증이란?

K-Fold 교차 검증은 데이터셋을 <font color="#FF4500">K개의 폴드</font>로 나누어 모델을 평가하는 방법이다. 각 폴드를 번갈아 테스트 세트로 사용하며, 나머지 폴드로 모델을 학습시킨다. 이 과정을 K번 반복해 얻은 테스트 MSE의 평균으로 최종 성능을 추정한다. 단일 테스트 세트의 불안정성을 줄이고, 데이터셋을 효율적으로 활용해 안정적인 성능 추정치를 제공한다.

## K-Fold 교차 검증의 단계별 과정

K-Fold 교차 검증은 체계적인 과정을 통해 모델의 성능을 평가한다. 다음은 단계별 설명이다:

1. 데이터셋을 <font color="#1E90FF">K개의 폴드</font>로 나눈다.
2. 한 폴드를 테스트 세트(보류 폴드)로 지정하고, 나머지 \( K-1 \)개 폴드로 모델을 학습시킨다.
3. 보류 폴드에서 테스트 MSE를 계산한다.
4. 이 과정을 K번 반복해 각 폴드가 한 번씩 테스트 세트로 사용되도록 한다.
5. 최종 테스트 MSE는 K번의 테스트 MSE 평균으로 계산된다:

$ \text{MSE} = \frac{1}{K} \sum\_{i=1}^K \text{MSE}\_i $

여기서 $\( \text{MSE}_i \)$는 $i$번째 폴드의 테스트 $MSE$다. 이 과정은 모델의 일반화 성능을 신뢰할 수 있게 평가한다.

## K 값 선택: 편향-분산 트레이드오프

K-Fold 교차 검증에서 K 값은 폴드의 수를 결정하며, <font color="#FFD700">편향-분산 트레이드오프</font>에 직접적인 영향을 미친다. K 값을 선택할 때는 다음을 고려해야 한다:

- **큰 K**: 폴드 수가 많아지면 각 테스트 세트는 작아지고, 훈련 세트는 데이터셋 전체에 가까워진다. 이는 <font color="#32CD32">편향은 낮아지지만 분산은 높아진다</font>. 예를 들어, $K=n (LOOCV)$에서는 편향이 최소화되지만 분산이 매우 커질 수 있다.
- **작은 K**: 폴드 수가 적으면 테스트 세트가 크고 훈련 세트가 작아져 <font color="#FF4500">편향은 높아지지만 분산은 낮아진다</font>. 예를 들어, K=2에서는 데이터의 절반만 훈련에 사용되므로 편향이 커진다.
- **최적의 K**: 실무에서는 $K=5$ 또는 $K=10$이 편향과 분산의 균형을 잘 맞춘다. 경험적으로 이 값들은 신뢰할 수 있는 테스트 $MSE$ 추정치를 제공하며, 계산 효율성도 적절하다.

K 값 선택은 모델의 일반화 성능을 좌우하므로, 데이터 크기와 계산 자원을 고려해 신중히 결정해야 한다.

## K-Fold 교차 검증의 장점

K-Fold 교차 검증은 단일 테스트 세트 방식의 한계를 극복하며 여러 가지 이점을 제공한다:

- **안정적인 추정치**: 다양한 훈련-테스트 세트 조합으로 테스트 MSE를 계산해 <font color="#1E90FF">편향 없는 추정치</font>를 얻는다.
- **데이터 활용 효율성**: 데이터셋을 여러 폴드로 나누어 모든 데이터를 학습과 테스트에 활용한다.
- **계산 효율성**: 모델을 K번만 학습시키므로, 데이터 크기가 큰 경우 LOOCV(모델을 n번 학습)보다 훨씬 빠르다. K=5나 K=10에서는 LOOCV와 유사한 결과를 얻으면서도 계산 시간이 단축된다.

이러한 장점 덕분에 K-Fold 교차 검증은 머신러닝 모델 평가의 표준 방법으로 자리 잡았다.

## K-Fold 교차 검증의 확장 기법

K-Fold 교차 검증은 다양한 상황에 맞게 변형된 기법들로 확장된다. 주요 확장 기법은 다음과 같다:

- **Repeated K-Fold**: K-Fold 교차 검증을 n번 반복하며, 매번 데이터를 무작위로 섞어 폴드를 구성한다. 이를 통해 테스트 MSE의 <font color="#32CD32">분산을 줄이고</font> 더 안정적인 추정치를 얻는다.
- **Leave-One-Out 교차 검증(LOOCV)**: K=n으로, 각 데이터 포인트를 테스트 세트로 사용한다. 편향은 최소화되지만, 계산 비용이 높고 분산이 커질 수 있다.
- **Stratified K-Fold**: 클래스 불균형 데이터에서 각 폴드가 전체 데이터의 클래스 비율을 대표하도록 만든다. 이는 <font color="#FF4500">분류 문제</font>에서 특히 유용하며, 더 나은 편향-분산 트레이드오프를 제공한다.
- **Nested Cross-Validation**: 외부 K-Fold 내에서 내부 K-Fold를 수행해 하이퍼파라미터 튜닝과 모델 평가를 동시에 진행한다. 모델 선택과 성능 추정을 분리해 과적합을 방지한다.
