---
layout: single
title: "ìì‹, ìì†, í˜•ì œ, ë¶€ëª¨"
categories: web_crawling
tag: [python, automation, web_crawling]
author_profile: false
# sidebar:
#   nav: "counts"
# search: false
# redirect_from:
#   - /coding/first-posting
use_math: true
---

# ğŸ‘‘ HTML êµ¬ì¡° ë¶„ì„

## ğŸŒŸ ìì‹ê³¼ ìì†

- ### `children()`
  - ì§ê³„ ìì‹ ìš”ì†Œë§Œ ë°˜í™˜
  - ì¦‰, findë¡œ ì°¾ì€ íƒœê·¸ì˜ ë°”ë¡œ ì•„ë˜ì˜ íƒœê·¸ë§Œ í¬í•¨

```python
import requests

from bs4 import BeautifulSoup

url = "https://choewj.github.io/machine_learning/built_in_data_type/"
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')

# page__content í´ë˜ìŠ¤ë¥¼ ê°€ì§€ëŠ” <section> íƒœê·¸ì˜ ìì‹ ìš”ì†Œë“¤ë§Œ ìˆœí™˜
for child in soup.find('section', {"class": "page__content"}).children:
    print(child.get_text().strip())  # í…ìŠ¤íŠ¸ ì¶œë ¥ í›„ ê³µë°± ì œê±°
```

ì¶œë ¥ ê²°ê³¼

    ëª©ì°¨
    ğŸ‘‘ ì‚¬ì´í‚·ëŸ° ë‚´ì¥ë°ì´í„°ğŸ‘ ê²°ê³¼ ë¶„ì„<class â€˜sklearn.utils._bunch.Bunchâ€™>í‚¤ê°’ë“¤ğŸ‘ ì£¼ìš” ë°ì´í„°ì…‹ ëª©ë¡

    ğŸ‘‘ ì‚¬ì´í‚·ëŸ° ë‚´ì¥ë°ì´í„°

    # ì‚¬ì´í‚·ëŸ° datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ë¶“ê½ƒ(iris) ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    from sklearn.datasets import load_iris

    iris_df = load_iris()  # ë¶“ê½ƒ(iris)ë°ì´í„° ë¡œë“œ

    print(type(iris_df))  # ë¶“ê½ƒ(iris) ë°ì´í„° íƒ€ì… ì¶œë ¥
    print()  # í•œ ì¹¸ ë„ìš°ê¸°
    print(f"ë¶“ê½ƒ(iris)ë°ì´í„° ì…‹ì˜ í‚¤:\n{iris_df.keys()}")  # ë¶“ê½ƒ(iris) ë°ì´í„° í‚¤ê°’ë“¤ ì¶œë ¥

    <ì¤‘ëµ>

- ### `descendants()`
  - ëª¨ë“  ìì† ìš”ì†Œë¥¼ ë°˜í™˜
  - í•˜ìœ„ì˜ ëª¨ë“  íƒœê·¸ë¥¼ í¬í•¨

```python
import requests

from bs4 import BeautifulSoup

url = "https://choewj.github.io/machine_learning/built_in_data_type/"
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')

# page__content í´ë˜ìŠ¤ë¥¼ ê°€ì§€ëŠ” <section> íƒœê·¸ì˜ ëª¨ë“  ìì† ìš”ì†Œë“¤ì„ ìˆœí™˜
for child in soup.find('section', {"class": "page__content"}).descendants:
    print(child.get_text().strip())  # í…ìŠ¤íŠ¸ ì¶œë ¥ í›„ ê³µë°± ì œê±°
```

ì¶œë ¥ ê²°ê³¼

    ëª©ì°¨

    ğŸ‘‘ ì‚¬ì´í‚·ëŸ° ë‚´ì¥ë°ì´í„°ğŸ‘ ê²°ê³¼ ë¶„ì„<class â€˜sklearn.utils.\_bunch.Bunchâ€™>í‚¤ê°’ë“¤ğŸ‘ ì£¼ìš” ë°ì´í„°ì…‹ ëª©ë¡

    ëª©ì°¨
    ğŸ‘‘ ì‚¬ì´í‚·ëŸ° ë‚´ì¥ë°ì´í„°ğŸ‘ ê²°ê³¼ ë¶„ì„<class â€˜sklearn.utils._bunch.Bunchâ€™>í‚¤ê°’ë“¤ğŸ‘ ì£¼ìš” ë°ì´í„°ì…‹ ëª©ë¡

    ëª©ì°¨
    ëª©ì°¨

    ëª©ì°¨

    ğŸ‘‘ ì‚¬ì´í‚·ëŸ° ë‚´ì¥ë°ì´í„°ğŸ‘ ê²°ê³¼ ë¶„ì„<class â€˜sklearn.utils._bunch.Bunchâ€™>í‚¤ê°’ë“¤ğŸ‘ ì£¼ìš” ë°ì´í„°ì…‹ ëª©ë¡
    ğŸ‘‘ ì‚¬ì´í‚·ëŸ° ë‚´ì¥ë°ì´í„°ğŸ‘ ê²°ê³¼ ë¶„ì„<class â€˜sklearn.utils._bunch.Bunchâ€™>í‚¤ê°’ë“¤ğŸ‘ ì£¼ìš” ë°ì´í„°ì…‹ ëª©ë¡
    ğŸ‘‘ ì‚¬ì´í‚·ëŸ° ë‚´ì¥ë°ì´í„°
    ğŸ‘‘ ì‚¬ì´í‚·ëŸ° ë‚´ì¥ë°ì´í„°
    ğŸ‘ ê²°ê³¼ ë¶„ì„<class â€˜sklearn.utils._bunch.Bunchâ€™>í‚¤ê°’ë“¤ğŸ‘ ì£¼ìš” ë°ì´í„°ì…‹ ëª©ë¡
    ğŸ‘ ê²°ê³¼ ë¶„ì„<class â€˜sklearn.utils._bunch.Bunchâ€™>í‚¤ê°’ë“¤
    ğŸ‘ ê²°ê³¼ ë¶„ì„
    ğŸ‘ ê²°ê³¼ ë¶„ì„
    <class â€˜sklearn.utils._bunch.Bunchâ€™>í‚¤ê°’ë“¤
    <class â€˜sklearn.utils._bunch.Bunchâ€™>
    <class â€˜sklearn.utils._bunch.Bunchâ€™>
    <class â€˜sklearn.utils._bunch.Bunchâ€™>
    í‚¤ê°’ë“¤
    í‚¤ê°’ë“¤
    í‚¤ê°’ë“¤
    ğŸ‘ ì£¼ìš” ë°ì´í„°ì…‹ ëª©ë¡
    ğŸ‘ ì£¼ìš” ë°ì´í„°ì…‹ ëª©ë¡
    ğŸ‘ ì£¼ìš” ë°ì´í„°ì…‹ ëª©ë¡

    <ì¤‘ëµ>

## ğŸŒŸ í˜•ì œ

- ### `next_siblings()`
  - ìê¸° ìì‹ (ê°ì±„)ë¥¼ ì œì™¸í•œ ê·¸ ë‹¤ìŒì— ìˆëŠ” í˜•ì œë“¤ì„ ë°˜í™˜

```python
import requests

from bs4 import BeautifulSoup

url = "https://choewj.github.io/machine_learning/built_in_data_type/"
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')

# page__content í´ë˜ìŠ¤ë¥¼ ê°€ì§€ëŠ” <section> íƒœê·¸ì˜ ëª¨ë“  ë‹¤ìŒ í˜•ì œ íƒœê·¸ë“¤ì„ ìˆœí™˜
for child in soup.find('section', {"class": "page__content"}).next_siblings:
    print(child.get_text().strip())
```

ì¶œë ¥ ê²°ê³¼

    íƒœê·¸:

    Data,
    ML,
    python



     ì¹´í…Œê³ ë¦¬:

    machine_learning


     ì—…ë°ì´íŠ¸: 2025-03-18

    ê³µìœ í•˜ê¸°
     Twitter
     Facebook
     LinkedIn

    ì´ì „
    ë‹¤ìŒ

- ### `previous_siblings()`
  - ìê¸° ìì‹ (ê°ì±„)ë¥¼ ì œì™¸í•œ ê·¸ ì „ì— ìˆëŠ” í˜•ì œë“¤ì„ ë°˜í™˜

```python
import requests

from bs4 import BeautifulSoup

url = "https://choewj.github.io/machine_learning/built_in_data_type/"
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')

# page__content í´ë˜ìŠ¤ë¥¼ ê°€ì§€ëŠ” <section> íƒœê·¸ì˜ ëª¨ë“  ì´ì „ í˜•ì œ íƒœê·¸ë“¤ì„ ìˆœí™˜
for child in soup.find('section', {"class": "page__content"}).previous_siblings:
    print(child.get_text().strip())
```

ì¶œë ¥ ê²°ê³¼

    ì‚¬ì´í‚·ëŸ°ì˜ ë‚´ì¥ë°ì´í„°





    2025-03-18





              1 ë¶„ ì†Œìš”

## ğŸŒŸ ë¶€ëª¨

### `parent`

```python
import requests

from bs4 import BeautifulSoup

url = "https://choewj.github.io/machine_learning/built_in_data_type/"
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')

# <thead> íƒœê·¸ì˜ ë¶€ëª¨ íƒœê·¸ì˜ ì´ì „ í˜•ì œ íƒœê·¸ë¥¼ ì°¾ì•„ì„œ í…ìŠ¤íŠ¸ë¡œ ì¶œë ¥
print(soup.find("thead").parent.find_previous_sibling().get_text())

```

ì¶œë ¥ ê²°ê³¼

    ğŸ‘ ì£¼ìš” ë°ì´í„°ì…‹ ëª©ë¡

```python
import requests

from bs4 import BeautifulSoup

url = "https://choewj.github.io/machine_learning/built_in_data_type/"
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')

# <thead> íƒœê·¸ì˜ ë¶€ëª¨ íƒœê·¸ì˜ ë‹¤ìŒ í˜•ì œ íƒœê·¸ë¥¼ ì°¾ì•„ì„œ í…ìŠ¤íŠ¸ë¡œ ì¶œë ¥
print(soup.find("thead").parent.find_next_sibling().get_text())
```

ì¶œë ¥ ê²°ê³¼

```
â€» ë³´ìŠ¤í„´ ë°ì´í„° ì…‹ì€ ì¸ì¢…ì°¨ë³„ ë…¼ë€ìœ¼ë¡œ ìµœê·¼ ì‚¬ì´í‚·ëŸ° ë°ì´í„°ì…‹ì—ì„œëŠ” ì‚­ì œë¨
```
